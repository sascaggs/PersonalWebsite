[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "CV.html",
    "href": "CV.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Graduate Research Fellow Human Complexity Lab Department of Anthropology The Ohio State University scaggs.32@osu.edu\n\n\n\nHuman Subsistence \\(\\times\\) Cooperation and Interspecies Coexistence \\(\\times\\) Dietary Diversity \\(\\times\\) Food Webs \\(\\times\\) Network Science \\(\\times\\) Complex Social-Ecological Systems \\(\\times\\) Community and Wildlife Ecology\n\n\n\n\n\n\n \n  \n    Year \n    Institution \n    Program \n    Degree \n  \n \n\n  \n    2021 \n    Ohio State University \n    Anthropology \n    PhD candidate \n  \n  \n    2018 \n    Oregon State University \n    Applied Anthropology \n    Master of Science \n  \n  \n    2016 \n    Boise State University \n    Anthropology \n    Bachelor of Science \n  \n\n\n\n\n\n\n\n\n\n\n \n  \n    Year \n    Citation \n  \n \n\n  \n    in prep \n    Scaggs, S. A., Nabors, S., Syed, Z., Rongjun, Q., Downey, S. S., (in prep). A comparative analysis of the swidden agriculture, landscape structure, and ecosystem enhancement. Philosophical Transactions of the Royal Society B.  NA \n  \n  \n    in review \n    Ross, C. T., Hooper, P., Smith, J. E., [and 101 others, including Scaggs, S., A.] (in review) Reproductive Inequality in Humans and Other Mammals. Proceedings of the National Academy of Sciences.  NA \n  \n  \n    in review \n    Downey, S. S., Walker, M., Moschler, J., Penados, F., Peterman, W., Rongjun, Q., Scaggs, S. A., Song, S. (in review). Intermediate-scale swidden disturbances increase canopy tree diversity in remotely-sensed images of Indigenous Maya community forests. Nature Sustainability. NA \n  \n  \n    2022 \n    Piperata, B., Scaggs, S., Dufour, D., Adams, I. (2022) Measuring food security: An introduction to tools for human biologists and ecologists. American Journal of Human Biology.  https://doi.org/10.1002/ajhb.23821 \n  \n  \n    2021 \n    Scaggs, S., Gerkey, D., McLaughlin, K. (2021). Linking subsistence harvest diversity and productivity to adaptive capacity in an Alaskan food sharing network. American Journal of Human Biology. Special Issue: Anthropological Insights on Adaptation and Climate Change, Vol. 33 (4): e23573.  https://doi.org/10.1002/ajhb.23573 \n  \n  \n    2021 \n    Kawa, N., Arceno, M. A., Goeckner, R., Hunter, C., Rhue, S., Scaggs, S., Biwer, M., Downey, S., Field, J., Gremillion, K., McCorriston, J., Willow, A., Newton, E., Moritz, M. (2021). Training Wicked Scientists for a World of Wicked Problems. Humanities & Social Sciences Communications. Vol. 8 (189). https://doi.org/10.1057/s41599-021-00871-1 \n  \n  \n    2020 \n    Downey, S., Gerkey, D., Scaggs, S. (2020). The Milpa Game: a field experiment investigating the social and ecological dynamics of Q'eqchi' Maya swidden agriculture. Human Ecology, Vol. 48: 423-438.  https://doi.org/10.1007/s10745-020-00169-x \n  \n  \n    2020 \n    Moritz, M., Scaggs, S., Shapiro, C., Hinkelman, S. (2020). Comparative Study of Territoriality across Forager Societies. Human Ecology, Vol. 48: 225-234.  https://doi.org/10.1007/s10745-020-00141-9 \n  \n  \n    2019 \n    Snopkowski, K., Demps, K., Scaggs, S., Griffiths, R., Fulk, K., May, S., Neagle, K., Downs, K., Eugster, M., Amend, T., Heath, J. (2019). Small Group Learning is Associated with Reduced Salivary Cortisol and Testosterone in Undergraduate Students. Journal of the Scholarship of Teaching and Learning, Vol. 19 (5): 36-52. https://doi.org/10.14434/josotl.v19i5.24230. \n  \n  \n    2017 \n    Scaggs, S. A., Fulk, K., Glass, D. J., Ziker, J. P. (2017) Framing charitable solicitation in a behavioral experiment: Cues derived from evolutionary theory of cooperation and anthropological economics. In Li, M., Tracer, D. P. (eds.) Interdisciplinary Perspectives on Fairness, Equity, and Justice, 153-178. Springer.  https://doi.org/10.1007/978-3-319-58993-0_10 \n  \n\n\n\n\n\n\n\n\n\n\n\nContribution matrix.\n\n\n\n\n\n\n\n\n\n\n\n \n  \n    Year \n    Title \n    Funding Agency \n    Amount \n  \n \n\n  \n    2021 \n    Doctoral Dissertation Research Improvement Grant (DDRIG) \n    Cultural Anthropology Program, National Science Foundation \n    $20,000 \n  \n  \n    2019 \n    Daniel T. Hughes Memorial Fund \n    Department of Anthropology, The Ohio State University \n    $300 \n  \n  \n    2019 \n    Pre-Dissertation Field Research Grant \n    Tinker Foundation, College of Latin American Studies, The Ohio State University \n    $1,750 \n  \n  \n    2018 \n    Graduate Research Fellowship (GRF) \n    Graduate Research Fellowship Program, National Science Foundation \n     \n  \n  \n    2018 \n    Graduate Research and Writing Residency \n    Spring Creek Project, Oregon State University \n    $250 \n  \n  \n    2015 \n    Special Undergraduate Recognition Award \n    Evolutionary Anthropology Society, American Anthropology Association \n    $250 \n  \n\n\n\n\n\n\n\n\n\n\n \n  \n    Year \n    Title \n    Meeting \n    Type \n  \n \n\n  \n    2021 \n    The Importance of Humans in Neotropical Food Webs \n    Fall Forum 2021, Translational Data Analytics Institute \n    Poster \n  \n  \n    2021 \n    Subsistence harvest diversity, social networks, and adaptive capacity to environmental change in Alaska. \n    90th American Association of Physical Anthropologists \n    Invited Symposium \n  \n  \n    2019 \n    Playing 'The Milpa Game': Using field experiments to investigate common pool resource dilemmas in Toledo District, Belize \n    118th American Anthropological Association \n    Podium \n  \n  \n    2018 \n    Subsistence harvest productivity and biodiversity in Alaskan social networks \n    117th American Anthropological Association \n    Podium \n  \n  \n    2018 \n    Exponential random graph modeling of productivity, diversity, and reciprocity in Alaskan food sharing networks \n    5th Northwest Evolution, Ecology, and Human Behavior Symposium \n    Poster \n  \n  \n    2017 \n    Dynamic Change, Social Networks, and Harvests: Levels of Resilience in Alaska \n    29th Human Behavior and Evolution Society \n    Poster \n  \n  \n    2017 \n    Stress: The effects of social and solitary learning on salivary hormones \n    29th Human Behavior and Evolution Society \n    Poster \n  \n  \n    2016 \n    The Solicitation of Charitable Donations: Experimental Evidence from Behavioral Economic Games \n    Boise State University Undergraduate Research Conference \n    Podium \n  \n  \n    2016 \n    Understanding Charitable Donations \n    Boise State University Advancement Team \n    Invited Talk \n  \n  \n    2016 \n    Endocrine stress response in college students to solitary and group learning \n    4th Northwest Evolution, Ecology, and Human Behavior Symposium \n    Poster \n  \n  \n    2016 \n    Four Pathways to Generosity \n    4th Northwest Evolution, Ecology, and Human Behavior Symposium \n    Poster \n  \n  \n    2015 \n    Four Pathways to Generosity: Evolutionary Mechanisms Differentially Affect Charitable Donations \n    114th American Anthropological Association \n    Podium"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Shane A. Scaggs",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\nGaussian models Part I\n\n\nUsing simulation to understand generalized linear models\n\n\n\n\nmodeling\n\n\nGLM\n\n\nsimulation\n\n\nstatistics\n\n\nbeginner\n\n\n\n\n\n\n\n\n\n\n\nShane A. Scaggs\n\n\n\n\n\n\n  \n\n\n\n\nNetwork size and structure\n\n\n\n\n\n\n\ntheory\n\n\nstructure\n\n\nsimulation\n\n\nscale\n\n\n\n\n\n\n\n\n\n\n\nDec 22, 2021\n\n\nShane A. Scaggs\n\n\n\n\n\n\n  \n\n\n\n\nBuilding simple multilevel models with {brms}\n\n\n\n\n\n\n\nstatistics\n\n\nBayesian\n\n\nmodeling\n\n\ndata analysis\n\n\n\n\n\n\n\n\n\n\n\nDec 10, 2021\n\n\nShane A. Scaggs\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021-12-10-building-simple-multilevel-models/index.html",
    "href": "posts/2021-12-10-building-simple-multilevel-models/index.html",
    "title": "Building simple multilevel models with {brms}",
    "section": "",
    "text": "Multilevel models are a kind of statistical model that estimate parameters at more than one level. They are very useful kind of model because they are suited to the hierarchical and nested organization of the world around us. In this post, I will demonstrate how to build, describe, and compare multilevel models using tools from brms.\nFor this demonstration, let’s model the palmerpenguins dataset made available on github by Allison Horst. These data contain morphometrics for three species of penguins – Chinstrap, Gentoo, and Adelie – and the names of the islands they inhabit in Antarctica."
  },
  {
    "objectID": "posts/2021-12-10-building-simple-multilevel-models/index.html#start-simple",
    "href": "posts/2021-12-10-building-simple-multilevel-models/index.html#start-simple",
    "title": "Building simple multilevel models with {brms}",
    "section": "Start simple",
    "text": "Start simple\nLet’s model penguin body mass (body_mass_g). A simple starting model would be to estimate the central tendency and variation in body masses across all penguins. We can do this by estimating the parameters mu (\\(\\mu\\)) and sigma (\\(\\sigma\\)) with a Gaussian family.\nFor now, we will use the default brms priors. You can view them by calling the model formula, data, and family:\n\nget_prior(body_mass_g ~ 1, \n          family = gaussian(), data = d)\n\n                     prior     class coef group resp dpar nlpar lb ub  source\n student_t(3, 4050, 889.6) Intercept                                  default\n    student_t(3, 0, 889.6)     sigma                             0    default\n\n\nThe model formula is truly as simple as it can be: body_mass_g ~ 1. We estimate a single fixed intercept.\n\nmod0 <- brm(family = gaussian(), data = d,\n            body_mass_g ~ 1)\n\n\n\n\nWe can examine the posterior estimates using posterior_summary(), which returns all fixed and random effect estimate by a <brmsfit> object. According to this model, the mean body mass (g) of all the Penguins is 4200.43, surrounded by 44.09 grams of error. This value is comparable to the value computed using base R (mean = 4201.75). This model also estimates a sigma value of 802.90, which is comparable to the standard deviation (sd = 801.95)\n\nposterior_summary(mod0)\n\n               Estimate   Est.Error        Q2.5       Q97.5\nb_Intercept  4202.24405 43.93026876  4115.67686  4289.96055\nsigma         804.00584 31.13987362   746.30603   865.65799\nlprior        -15.39316  0.03575543   -15.46696   -15.32878\nlp__        -2781.47280  0.98978812 -2784.21080 -2780.48072\n\n\nIf we generate 4000 draws from this model, and graph them, the distribution looks something like this:\n\n\n\n\n\nPosterior distribution of body mass (g)."
  },
  {
    "objectID": "posts/2021-12-10-building-simple-multilevel-models/index.html#species-variation-fixed-and-random",
    "href": "posts/2021-12-10-building-simple-multilevel-models/index.html#species-variation-fixed-and-random",
    "title": "Building simple multilevel models with {brms}",
    "section": "Species variation, fixed and random",
    "text": "Species variation, fixed and random\nA sensible biologist might point out that body mass probably varies across each species of penguin. We can assess this by adding a fixed effect of species to our model that will estimate the body mass for each species. It will not, however, help us understand how body mass varies within each species. To do that, we need estimate random intercepts for each species group. We’ll fit both models to illustrate the difference.\nFor the fixed effect model, we add the species factor to our model formula:\n\nbody_mass_g ~ 1 + species\n\nto estimate a fixed intercept for each of the species groups in the dataset.\n\nmod1a <- brm(data = d, family = gaussian(),\n             body_mass_g ~ 1 + species)\n\n\n\n\nWe can examine the estimates by calling the model object inside the fixef() function.\n\nfixef(mod1a)\n\n                   Estimate Est.Error      Q2.5     Q97.5\nIntercept        3701.17778  36.52792 3629.7886 3774.4572\nspeciesChinstrap   31.57681  67.58873 -101.7963  163.4163\nspeciesGentoo    1374.24868  54.51842 1269.7078 1482.2137\n\n\nHere we see that the body mass of Adelie – the reference category for Intercept – and Chinstrap differ by just over 30 grams, while the mean for Gentoo is more than 1000 grams larger. Just how much these body mass measurements overlap is easier to see if we graph the posterior.\n\n\n\n\n\nPosterior distribution of body mass (g) for each penguin species.\n\n\n\n\nTo estimate random intercepts for each species, rather than fixed intercepts, we use the following model formula:\n\nbody_mass_g ~(1|species)\n\n\nmod1b <- brm(data = d, family = gaussian(),\n             body_mass_g ~ (1|species))\n\n\n\n\nThis model estimates a “global” fixed intercept:\n\nfixef(mod1b)\n\n          Estimate Est.Error     Q2.5    Q97.5\nIntercept  4130.29  459.9165 3156.383 5029.404\n\n\nand then separate random intercepts for each species, reported as differences from the global intercept:\n\nranef(mod1b)\n\n$species\n, , Intercept\n\n           Estimate Est.Error        Q2.5     Q97.5\nAdelie    -427.7364  461.8709 -1340.36322  554.2313\nChinstrap -394.6471  461.6474 -1314.66820  588.0133\nGentoo     941.2958  459.9377    28.34081 1914.2185\n\n\nUltimately, this model will produce posterior distributions that look very similar to the fixed effect model:\n\n\n\n\n\nPosterior distribution of body mass (g) based on random intercepts for each penguin species.\n\n\n\n\nHowever, there is a key difference between the fixed and random effects models. The random effects model has a much greater amount of uncertainty when compared to the fixed effects. This can be seen in the following dotplot, which shows the coefficient estimates for each model and the error around these estimates.\n\n\n\n\n\nIntercept and beta coefficients fixed and random effects models. Lines indicate estimated error.\n\n\n\n\nThere is a tendency to view high uncertainty as a marker of defeat. This should not be the case. Having a better estimation of model uncertainty (combined with good theory) is a necessary condition for valid causal inference."
  },
  {
    "objectID": "posts/2021-12-10-building-simple-multilevel-models/index.html#endnotes",
    "href": "posts/2021-12-10-building-simple-multilevel-models/index.html#endnotes",
    "title": "Building simple multilevel models with {brms}",
    "section": "Endnotes",
    "text": "Endnotes\n\nAs with all MCMC models, your results may differ slightly than mine. I did not bother to set the seed = parameter in brm, so you’ll not be able to reproduce each decimal exactly.\nI’ve hidden many of the plotting details for brevity. I can elaborate more on these in future posts. For now, check out the work of Solomon Kurz to learn more about using tidyverse and tidybayes to visualize Bayesian models."
  },
  {
    "objectID": "posts/2021-12-22-network-size-and-structure/index.html",
    "href": "posts/2021-12-22-network-size-and-structure/index.html",
    "title": "Network size and structure",
    "section": "",
    "text": "This post is also available on the Social Ecological Networks Group.\n\n\n\nThe size of a network is determined by the number of vertices and edges within it, and different size networks have different structural properties. This is obviously true if social processes like homophily, preferential attachment, or triadic closure influence network size, but it is also true for randomly generated networks.\nHow do properties like density, sparseness, degree distribution, or connectivity change as the number of vertices in a network increases? To find out, I set up a few computational experiments for directed and undirected networks.\n\nSparse networks\nA graph is considered sparse if the number of edges, \\(m\\), is less the number of vertices, \\(n\\); a value given by \\(m < O(n)\\), the orthogonal group. As the number of vertices increases, the density at which a network is considered sparse decreases. Additionally, this negative relationship differs for undirected and directed networks, because the maximum edges in a directed graph is given by \\(n(n-1)\\) whereas in an undirected graph, it is \\(n(n-1)/2\\).\nGenerally speaking, the point at which any network becomes sparse (\\(S\\)) is the ratio between the orthogonal set and the maximum number of possible edges. For a directed network, this is given by:\n\\[S = \\frac{O(n)}{n(n-1)}\\]\nAnd for an undirected network:\n\\[S = \\frac{O(n)}{n(n-1)/2}\\]\nSo if we vary \\(n\\) and plot the value of \\(S\\), we can see how this threshold changes for different size networks. Here is a function to do this:\n\nsparsepoint <- function(n, directed=F) {\n  if ( directed == F  )   { n / (n*(n-1)/2) }\n  else if ( directed == T ) { n / (n*(n-1))   }\n  else { \n    print('Must be TRUE or FALSE.')\n  }\n}\n\n\nsparsepoint(100)\n\n[1] 0.02020202\n\nsparsepoint(100, directed = T)\n\n[1] 0.01010101\n\n\nNow we can create a sequence of \\(n\\) values and graph the results. Figure 1 shows what this function looks like as \\(n\\) increases from 1 to 10000. When a network is smaller than 1000 vertices, the sparsepoint is occurs between 0.5% and 2% density. The dropoff occurs more slowly for undirected networkss. Above 1000 vertices, the sparsepoint for both directed and undirected networks begins to converge on 0.01% density.\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nThe density at which a network is considered sparse as a function of the number of vertices.\n\n\n\n\n\n\nDegree distribution\nFor a network of any size, as the edge density increases, the degree distribution is expected to become more uniform, with the mean degree starting to approximate \\(n\\). To see how degree distribution changes with edge density, we can calculate degree for each node across a variety of density levels. Here I do this for networks with 10, 75, and 150 vertices, each ranging in density from 0.01 to 0.99.\n\nd <- seq(0.01,0.99, length.out=11)\nl <- list()\nfor(i in seq_along(d)) {\n  l[[i]] <- network(10, directed = F, density = d[i])\n  m <- data.frame(lapply(l, degree))\n}\ncolnames(m) <- paste0('Density',d)\nhead(m)\n\n  Density0.01 Density0.108 Density0.206 Density0.304 Density0.402 Density0.5\n1           0            0            2            6            8         12\n2           0            0            4            8            8         10\n3           0            0            4           10            8          6\n4           0            2            4            8           10         10\n5           0            0            6            8            8         10\n6           0            0            2            6            6          6\n  Density0.598 Density0.696 Density0.794 Density0.892 Density0.99\n1           10           16           16           14          18\n2           10           12           18           16          18\n3            4           12           18           14          18\n4           10           16           14           16          18\n5           14           10           14           14          12\n6           12           10           18           16          18\n\n\nI do this for each network size and then plot the distributions to compare.\n\n\n\n\n\nA comparison of the degree distributions at increasing levels of density for three different size networks.\n\n\n\n\nThe degree distributions of networks that have only a couple hundred vertices or less can overlap quite a bit across different levels of edge density. Large networks have a much more precise degree distribution. This makes it clear why descriptive statistics that depend on density cannot easily be compared between different networks, unless the networks are large.\n\n\nAverage Path Length\nThe length of a path between two vertices is determined by the number of vertices that lie between them. A direct path between two vertices is equal to 1.\nWe observed that as \\(m\\) increases, mean degree approaches \\(n\\). We can expect that when mean degree is approximately \\(n\\), the average path length should be approximately 1.\nThe function below accepts a sequence of densities and a number of vertices, and returns the mean degree and average path length at each level of density.\n\nl <- list()\napl <- c()\n\nDegApl <- function(n, directed = F, d, seed=777) {\n  for(i in seq_along(d)) {\n    l[[i]] <- network(n, directed = directed, \n                      density = d[i], seed=seed)\n    m <- data.frame(lapply(l, degree))\n    k <- lapply(l, geodist, inf.replace = 0, count.paths = F)\n    apl[i] <- mean(k[[i]]$gdist)\n  }\n  remove(l,k) \n  colnames(m) <- c(1:length(d))\n  mD <- apply(m, 2, mean)\n  return(cbind(apl,mD,n,d))\n}\n\nNow we can explore relationships between these variables by running this function on networks with different sizes. Here we use a long sequence of densities to better approximate relationships.\n\n\n\nWe can expect that mean degree and density are positively correlated. But what is the shape of this relationship?\n\n\n\n\n\nThe association between edge density and mean degree is approximately linear.\n\n\n\n\nAverage path length should also systematically vary with density, but it is unclear what the shape of this relationship will look like. For instance, at low density, many paths = 0 because many vertices are isolated. However, dense networks should have short paths, as most vertices are directly connected to each other.\n\n\n\n\n\nExplosive percolation of average path length\n\n\n\n\nAt very low density (0.01), the average path length is essentially 0, but just a small increase in density leads to explosive increase in the average path length. This phenomenon is an example of explosive percolation, and it occurs because even randomly added edges have a chance of connecting isolated vertices to a large component.\nThis explosion happens even sooner for networks with a greater number of vertices. Exactly when does this percolation happen? At the sparsepoint (!) which we know varies systematically as a function of \\(n\\). Because the density at which a network goes from being sparse to not sparse decreases as a function of network size, we see explosive changes in average path length sooner and sooner as network size increases.\nAs we continue to increase density, the average path length decreases because the number of direct paths between vertices that are part of the largest component continues to increase, and this drives down the average path length. Eventually the average path length for networks of all sizes converges on 1."
  },
  {
    "objectID": "posts/2023-2-10-using-simulation-to-understand-glm-part1/index.html",
    "href": "posts/2023-2-10-using-simulation-to-understand-glm-part1/index.html",
    "title": "Using simulation to undersand generalized linear models",
    "section": "",
    "text": "Prologue\nConventional statistics course that I’ve taken in the past have been incredibly unsatisfying. The material was dry and technical and this made only a very small portion of the content seem all that practical.\nI believe the essential problem with most conventional statistics courses is that they tend to emphasize statistical theory over statistical practice. This makes doing statistics feel very static, despite the reality that data analysis is a dynamic, iterative process.\nFast forward to 2023 and I’m having students and colleagues ask me modeling questions that they clearly didn’t have answered in their analytical training. They want to know which “test” to run and which buttons to click. Each conversation I have like this gives more motivation to help researchers shift from testing to modeling.\nThe goal of this post is to start developing some primers for statistical models. Each post in this series will use simulation to understand a different model family in generalized linear modeling.\n\n\nBackground\nWhether I’m working on Bayesian or frequentist models, the analytical workflow that I use today is based on the free lectures provided by Richard McElreath based on his book Statistical Rethinking. They are fantastic and mind opening.\n\n\nGetting started\nLet’s begin by just thinking about the mechanics of a linear model. First let’s look at the equation for such a model:\n\\[Y_i = \\beta_0 + \\beta_1 X_i\\] This equation looks more formidable than it is. The placeholders \\(X_i\\) and \\(Y_i\\) represent variables. These are values that we will include in the model from our data. The little \\(i\\) is an index; you can sort of think of it like row \\(i\\). When you are viewing an equation, you can look for these indices to determine which parameters of the equation are likely to vary.\nThe greek letters are parameters that we estimate. In this case, \\(\\beta_0\\) is an intercept parameter – the expected mean value when \\(X_i\\) is 0. You’ll also see this parameter symbolized with the greek letter \\(\\alpha\\). The \\(\\beta_1\\) parameter is a slope, a scalar that influences the relationship between \\(X_i\\) and \\(Y_i\\).\n\n\nSimulating variables\nWe won’t be working with data at the moment. Instead we will simulate. So let’s start with \\(X\\). Let’s imagine we have a variable with a mean value of 10 and a standard deviation of 2.\n\nN = 400\nx = rnorm( n=N, mean=10, sd=2 )\n\nHaving generated this variable x using random numbers from a Gaussian distribution, we get something similar to a bell shaped curve.\n\n\n\n\n\nNow let’s do the same for \\(Y\\), using a mean of 7 and a standard deviation of 1.5.\n\ny = rnorm( n=N, mean=7, sd=1.5 )\n\nNow what happens if we plot the association between these two variables?\n\n\n\n\n\nBecause both x and y were generated independent of each other, there is no discernible relationship between them. This implies that the estimated value of \\(\\beta_1\\) will be near 0. We can confirm this with a model.\n\nd = data.frame(x,y)\nmodel1 = glm( formula = y ~ x, data=d, family = gaussian ) \nsummary(model1)\n\n\nCall:\nglm(formula = y ~ x, family = gaussian, data = d)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.9943  -0.9382  -0.0495   0.9391   3.9720  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  6.81178    0.32457   20.99   <2e-16 ***\nx            0.03053    0.03181    0.96    0.338    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 1.800798)\n\n    Null deviance: 718.38  on 399  degrees of freedom\nResidual deviance: 716.72  on 398  degrees of freedom\nAIC: 1374.4\n\nNumber of Fisher Scoring iterations: 2\n\n\nIndeed, the coefficient esimate for x – the slope – is just about 0. And because the relationship is pretty much non-existent, the intercept parameter \\(\\beta_0\\) is estimated to be approximately the mean value for y.\n\n\nForm a relationship\nSo how would we go about linking x and y? Well we need to provide value for the slope parameter. I find this a bit easier to think about if we write a function.\n\nlinear = function( x, b0, b1 ) {\n    y = b0 + b1*x\n    data.frame(x,y)\n}\n\nNow suppose we want there to be a negative relationship between x and y. We need to provide a negative value for b1.\n\nx = rnorm( n=N, mean=10, sd=2 )\nsim1 = linear( x=x, b0 = 7, b1 = -1.5 )\n\nNotice that we dont actually provide a vector of Y values this time. This is because they are generated by the function, rather than by sampling from a Gaussian distribution.\nLet’s plot these results and see what we find.\n\n\n\n\n\nSo we have enforced a perfect linear relationship between x and y. But wouldn’t we have expected a bit more variation rather than a perfect line? Indeed, in a sense we have lost the sd = 1.5 that we originally included when we generated y the first time. To include it, we need a different equation.\n\\[Y_i = \\beta_0 + \\beta_1 X_i + e_i\\] This term \\(e_i\\) is an “error” term. It is the residual deviance that is left unexplained by the other parameters in the equation.\nLet’s think about this another way. The original mean and sd used in y = rnorm(N, 7, 1.5) has been moved to the \\(\\beta_0\\) and the \\(e_i\\). We no longer supply the mean, but instead we estimated it as \\(\\beta_0\\) with some residual error, \\(e_i\\) left over.\nLet’s amend our function.\n\nlinear = function( x, b0, b1, e ) {\n    y = b0 + b1*x + e\n    data.frame(x,y)\n}\n\nNow let’s supply a constant value for e in this function; how about 1.5 like we used before?\n\nx = rnorm( n=N, mean=10, sd=2 )\nsim1 = linear( x=x, b0 = 7, b1 = -1.5, e = 2 )\n\n\n\n\n\n\nThat did really work did it. Why not? Well if we look a bit closer, we see that all that has happened is the value 2 was added on at the end. This is effectively like setting b0 to 9 instead of 7. What really need is a distribution of error, centered on 0 and deviating by 1.5.\n\nx = rnorm( n=N, mean=10, sd=2 )\ne = rnorm( n=N, mean=0, sd=1.5 )\nsim1 = linear( x=x, b0 = 7, b1 = -1.5, e=e )\n\n\n\n\n\n\nThat looks a bit more like what we might expect. But if it really is true that we’re just adding some error onto the end, we could get the same result if we don’t use e at all and instead supply our original y generated with rnorm in place of b0.\n\nx = rnorm( n=N, mean=10, sd=2 )\nsim1 = linear( x=x, b0 = rnorm( n=N, mean=7, sd=1.5), b1 = -1.5, e=0 )\n\n\n\n\n\n\nThis just shows that the generative process will work the same way. However, in practice, it will still be useful to use e. In future example, we might return to this approach as a way to created random intercepts.\n\n\nFit the model again\nNow that we have out generated data set, let’s try rerunning the glm from above.\n\nmodel1 = glm( formula = y ~ x, data=sim1, family = gaussian ) \nsummary(model1)\n\n\nCall:\nglm(formula = y ~ x, family = gaussian, data = sim1)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-5.156  -0.926   0.071   1.025   5.219  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  7.20368    0.35680   20.19   <2e-16 ***\nx           -1.51101    0.03502  -43.15   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 2.209865)\n\n    Null deviance: 4993.90  on 399  degrees of freedom\nResidual deviance:  879.53  on 398  degrees of freedom\nAIC: 1456.3\n\nNumber of Fisher Scoring iterations: 2\n\n\nThis time, we recover our slope parameter \\(\\beta_1\\) and we more accurately recover our intercept parameter \\(\\beta_0\\)."
  }
]